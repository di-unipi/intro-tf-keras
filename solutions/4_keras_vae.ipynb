{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility libraries\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Core libraries\n",
    "import numpy as np\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model  # Model used by Functional API\n",
    "from keras.layers import Dense, Lambda, Input  # Lambda and Input used by Functional API\n",
    "from keras import losses\n",
    "from keras import optimizers\n",
    "\n",
    "# For variational auto-encoder\n",
    "from keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt # For plotting purposes\n",
    "\n",
    "from keras.callbacks import TensorBoard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension (for visualization purposes)\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's define a Variational Autoencoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![VAE](https://miro.medium.com/v2/resize:fit:1400/1*Qd1xKV9o-AnWtfIDhhNdFg@2x.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's define a function that provides the epsilon of the picture and multiplies it with Sigma (the variance associated with the latent representation). We are not interested in the math behind it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reparameterization trick (no need to know the details)\n",
    "def sampling(args):\n",
    "    \"\"\"\n",
    "    Reparameterization trick by sampling from an isotropic unit Gaussian.\n",
    "    \n",
    "    Arguments\n",
    "        args (tensor): mean and log of variance of Q(z|X)\n",
    "    Returns\n",
    "        z (tensor): sampled latent vector\n",
    "    \"\"\"\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]  # get dimension of mini-batch\n",
    "    dim = K.int_shape(z_mean)[1]  # get dimension of each z\n",
    "\n",
    "    # by default, random_normal has mean = 0 and std = 1.0\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of VAE and its hyperparameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Hyperparameters__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_dim = 256  # Hidden units of the MLP\n",
    "batch_size = 128\n",
    "latent_dim = 2  # Dimension of the compressed input encoding our digit\n",
    "epochs = 20\n",
    "learning_rate = 1e-3\n",
    "input_shape = (784,)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Encoder__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=input_shape, name='encoder_input')  #  The image is the input of our Encoder \n",
    "h = Dense(intermediate_dim, activation='relu')(inputs)  # A Dense layer compresses the input\n",
    "# First Output of the encoder\n",
    "z_mean = Dense(latent_dim, activation='linear', name='z_mean')(h)  # Further compression into latent space for mean\n",
    "\n",
    "# Second Output of the encoder\n",
    "z_log_var = Dense(latent_dim, name='z_log_var')(h)  # Further compression into latent space for log_var\n",
    "\n",
    "# Third Output of the encoder\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "\n",
    "# Instantiate the Encoder as a Model, by specifying its inputs and outputs\n",
    "encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "encoder.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Decoder__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_inputs = Input(shape=(latent_dim,), name='z')\n",
    "h = Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
    "outputs = Dense(input_shape[0], activation='sigmoid')(h)\n",
    "\n",
    "# Instantiate the Decoder as a Model, by specifying its inputs and outputs\n",
    "decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "decoder.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__VAE__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate VAE model \n",
    "outputs = decoder(encoder(inputs)[2])\n",
    "\n",
    "vae = Model(inputs, outputs, name='vae_mlp')\n",
    "vae.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Loss definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_vae_loss(vae, encoder_inputs, decoder_outputs, z_mean, z_log_var, original_dim):\n",
    "    \n",
    "    reconstruction_loss = losses.mse(inputs, outputs)  # Start with the Mean Squared Error\n",
    "    reconstruction_loss *= original_dim  # we will average later! This is now the \"Squared Error\"\n",
    "    \n",
    "    # Compute the KL divergence (no need to know the math details here), which is our additional regularization term\n",
    "    kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "    kl_loss = K.sum(kl_loss, axis=-1)\n",
    "    kl_loss *= -0.5\n",
    "    \n",
    "    # Recompute the mean (over the examples) of the reconstruction error + regularization term\n",
    "    vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "    \n",
    "    # Add the loss to the model before compiling it\n",
    "    vae.add_loss(vae_loss)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's prepare the VAE loss, which is a reconstruction error + a regularization term\n",
    "add_vae_loss(vae, inputs, outputs, z_mean, z_log_var, original_dim=input_shape[0])\n",
    "vae.compile(optimizer=optimizers.Adam(lr=learning_rate))  # Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs_vae\n",
    "\n",
    "# Set up a log folder in which we will store the output to be displayed on TensorBoard\n",
    "logdir = \"logs_vae/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=logdir)\n",
    "\n",
    "# Chekpoint path for storing our model\n",
    "checkpoint_path = \"checkpoints/vae/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Train the Model!\n",
    "# Note: fit has also the chance to specify a validation split percentage\n",
    "print('# Fit model on training data')\n",
    "history = vae.fit(x_train,\n",
    "                  epochs=epochs,\n",
    "                  batch_size=batch_size,\n",
    "                  validation_split=0.1,\n",
    "                  callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize your model\n",
    "%tensorboard --logdir {logdir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(models,\n",
    "                 data,\n",
    "                 batch_size=128,\n",
    "                 model_name=\"vae_mnist\"):\n",
    "    \"\"\"\n",
    "    Plots labels and MNIST digits as a function of the 2D latent vector\n",
    "    Args:\n",
    "        models (tuple): encoder and decoder models\n",
    "        data (tuple): test data and label\n",
    "        batch_size (int): prediction batch size\n",
    "        model_name (string): which model is using this function\n",
    "    \"\"\"\n",
    "\n",
    "    encoder, decoder = models\n",
    "    x_test, y_test = data\n",
    "    os.makedirs(model_name, exist_ok=True)\n",
    "\n",
    "    filename = os.path.join(model_name, \"vae_mean.png\")\n",
    "    # display a 2D plot of the digit classes in the latent space\n",
    "    z_mean, _, _ = encoder.predict(x_test,\n",
    "                                   batch_size=batch_size)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=y_test)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.savefig(filename)\n",
    "    plt.show()\n",
    "\n",
    "    filename = os.path.join(model_name, \"digits_over_latent.png\")\n",
    "    # display a 30x30 2D manifold of digits\n",
    "    n = 30\n",
    "    digit_size = 28\n",
    "    figure = np.zeros((digit_size * n, digit_size * n))\n",
    "    # linearly spaced coordinates corresponding to the 2D plot\n",
    "    # of digit classes in the latent space\n",
    "    grid_x = np.linspace(-4, 4, n)\n",
    "    grid_y = np.linspace(-4, 4, n)[::-1]\n",
    "\n",
    "    for i, yi in enumerate(grid_y):\n",
    "        for j, xi in enumerate(grid_x):\n",
    "            z_sample = np.array([[xi, yi]])\n",
    "            x_decoded = decoder.predict(z_sample)\n",
    "            digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "            figure[i * digit_size: (i + 1) * digit_size,\n",
    "                   j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    start_range = digit_size // 2\n",
    "    end_range = (n - 1) * digit_size + start_range + 1\n",
    "    pixel_range = np.arange(start_range, end_range, digit_size)\n",
    "    sample_range_x = np.round(grid_x, 1)\n",
    "    sample_range_y = np.round(grid_y, 1)\n",
    "    plt.xticks(pixel_range, sample_range_x)\n",
    "    plt.yticks(pixel_range, sample_range_y)\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.imshow(figure, cmap='Greys_r')\n",
    "    plt.savefig(filename)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results((encoder, decoder),\n",
    "             (x_test, y_test),\n",
    "             batch_size=batch_size,\n",
    "             model_name=\"vae_mlp\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction Loss to perform anomaly detection\n",
    "__If reconstruction loss is above a certain threshold, then we consider the input as an anomaly.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_test = vae.predict(x_test)  # let's reconstruct the test input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the squared error for each example\n",
    "squared_error = np.sum(np.power((x_test - reconstructed_test), 2), axis=1)/(input_shape[0])\n",
    "\n",
    "# Plot the histogram of the reconstruction errors per image\n",
    "plt.hist(squared_error)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some reason (i.e., model selection), we know that 0.07 is a good threshold to decide whether an input is an anomaly or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the desired threshold\n",
    "threshold = 0.07\n",
    "\n",
    "# Now let's perturbate a test example\n",
    "sample = x_test[0]\n",
    "plt.imshow(np.reshape(sample, (28, 28)), cmap='gray')\n",
    "\n",
    "#perturbated_sample = sample + np.random.randint(0,2, size=(mnist_img_rows*mnist_img_cols))\n",
    "perturbated_sample = sample\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(np.reshape(perturbated_sample, (28, 28)), cmap='gray')\n",
    "\n",
    "# Add the \"batch\" dimension\n",
    "perturbated_sample = np.expand_dims(perturbated_sample, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_sample = vae.predict(perturbated_sample)  # let's reconstruct the test input\n",
    "\n",
    "# Compute the squared error for each example\n",
    "squared_error = np.sum(np.power((perturbated_sample - reconstructed_sample), 2), axis=1)/(input_shape[0])\n",
    "\n",
    "print(f'Reconstruction error is {squared_error[0]}, is this an anomaly? --> {bool(squared_error > threshold)}')\n",
    "\n",
    "plt.imshow(np.reshape(reconstructed_sample, (28, 28)), cmap='gray')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise #1: Change the model above to implement a Deep Neural Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![DeepAE](https://upload.wikimedia.org/wikipedia/commons/2/28/Autoencoder_structure.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
